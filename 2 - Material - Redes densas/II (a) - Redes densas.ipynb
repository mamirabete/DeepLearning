{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhiKhQn123F8"
      },
      "source": [
        "# II - Redes Densas\n",
        "Este ejemplo demuestra la construcción, entrenamiento y evaluación de una red neuronal densa utilizando TensorFlow y Keras para el problema de clasificación de imágenes del conjunto de datos MNIST. La arquitectura del modelo incluye capas densas con activaciones ReLU y Dropout para la regularización, y una capa\n",
        "de salida con activación Softmax para producir probabilidades de clasificación. El modelo se entrena con el optimizador Adam y la función de pérdida de entropía cruzada categórica, monitoreando la precisión tanto en el conjunto de entrenamiento como en el de validación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPrhyJFX23F-"
      },
      "source": [
        "## 1. Importar librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2A3Uv_l23F_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PqaBZnz23GA"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "from tensorflow.keras.metrics import MSE\n",
        "from tensorflow.keras.optimizers import Adadelta\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sia1w94423GA"
      },
      "source": [
        "## Parametros de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJwOogPy23GA"
      },
      "outputs": [],
      "source": [
        "lr = 1.0\n",
        "epochs = 20\n",
        "batch_size = 128\n",
        "np.random.seed(14)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwtawmH423GA"
      },
      "source": [
        "## 2. Cargar y visualizar el dataset\n",
        "Se carga el conjunto de datos MNIST, que contiene imágenes de dígitos manuscritos (0-9). Luego, los datos se normalizan y se convierten a categorías:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "G7gw6dxV23GB"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "n_classes = np.max(np.unique(y_train)) + 1\n",
        "\n",
        "print(\"Verificamos la cantidad de clases = %d\" % (n_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wrMM6rC23GB"
      },
      "outputs": [],
      "source": [
        "num = 25\n",
        "images = x_train[:num]\n",
        "labels = y_train[:num]\n",
        "num_row = 5\n",
        "num_col = 5\n",
        "fig, axes = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\n",
        "for i in range(num):\n",
        "    ax = axes[i//num_col, i%num_col]\n",
        "    ax.imshow(images[i], cmap='gray')\n",
        "    ax.set_title('Label: {}'.format(labels[i]))\n",
        "    ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Hdr__U123GB"
      },
      "source": [
        "### Preparacion de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4O-75S823GB"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHMihtQA23GC"
      },
      "outputs": [],
      "source": [
        "y_train = to_categorical(y_train, n_classes)\n",
        "y_test = to_categorical(y_test, n_classes) #one-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDybybQ323GC"
      },
      "outputs": [],
      "source": [
        "x_train.shape = (x_train.shape[0], np.prod(x_train.shape[1:]))\n",
        "x_test.shape = (x_test.shape[0], np.prod(x_test.shape[1:]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7W82Exo23GC"
      },
      "source": [
        "## 3. Contrucción del modelo\n",
        "Se define un modelo secuencial con capas densas (Dense). Se utiliza la función de activación ReLU en las capas ocultas y Softmax en la capa de salida:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0EusB8L23GC"
      },
      "outputs": [],
      "source": [
        "# Model\n",
        "#---------------------------------------------------------------------#\n",
        "input_layer = Input(shape=x_train.shape[1:])\n",
        "dense_1 = Dense(512, activation='relu') (input_layer) # números de neuronas potencias de 2\n",
        "# Se aplica dropout con una tasa del 20%\n",
        "# dropout_1 = Dropout(0.20) (dense_1) # ctrl + /\n",
        "dense_2 = Dense(512, activation='relu') (dense_1)\n",
        "# dropout_2 = Dropout(0.20) (dense_2)\n",
        "dense_3 = Dense(128, activation='relu') (dense_2)\n",
        "# dropout_3 = Dropout(0.20) (dense_3)\n",
        "output_layer = Dense(n_classes, activation='softmax') (dense_3)\n",
        "#---------------------------------------------------------------------#\n",
        "model = Model(input_layer, output_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Arquitectura de la red neuronal\n",
        "La elección de la arquitectura de una red neuronal, incluyendo el número de capas y el número de neuronas en cada capa, es una parte crucial del diseño del modelo y puede influir significativamente en su rendimiento.\n",
        "La arquitectura elegída del modelo en el ejemplo está basada en una combinación de principios teóricos y prácticas empíricas. Las capas densas con 500 y 100 neuronas permiten al modelo aprender características complejas y abstractas, mientras que la capa de salida con 10 neuronas corresponde a las clases (0-9) de salida. Experimentar con diferentes configuraciones y utilizar técnicas de regularización ayuda a encontrar un balance óptimo entre capacidad y generalización.\n",
        "\n",
        "### Uso de la Función Dropout en la Construcción del Modelo\n",
        "La función Dropout se utiliza en la construcción de redes neuronales densas como una técnica de regularización para prevenir el sobreajuste (overfitting). El sobreajuste ocurre cuando un modelo aprende demasiado bien los detalles y el ruido del conjunto de datos de entrenamiento, lo que resulta en un mal desempeño en datos no vistos.\n",
        "\n",
        "### ¿Qué es Dropout?\n",
        "Dropout es una técnica en la que, durante el entrenamiento de la red neuronal, se \"desconectan\" aleatoriamente un porcentaje de neuronas en cada capa durante cada iteración. Esto significa que las conexiones de estas neuronas no se consideran en el proceso de forward y backward propagation durante esa iteración específica. Las neuronas \"desconectadas\" cambian en cada iteración, lo que fuerza a la red a no depender excesivamente de ninguna neurona en particular.\n",
        "\n",
        "### Beneficios de Dropout\n",
        "* Prevención del Sobreajuste\n",
        "* Mejora en la Robustez del Modelo\n",
        "* Regularización Eficiente\n"
      ],
      "metadata": {
        "id": "PFMfSZde66qa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W39K7YeY23GC"
      },
      "source": [
        "## 4. *Compilación del Modelo*\n",
        "Se compila el modelo especificando el optimizador, la función de pérdida y las métricas a monitorear:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgmtg7Ou23GD"
      },
      "outputs": [],
      "source": [
        "Adadelta_optimizer = Adadelta(learning_rate=lr, rho=0.95)\n",
        "model.compile(optimizer=Adadelta_optimizer, loss='categorical_crossentropy', metrics=['acc', 'mse'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Componentes del Resumen del Modelo**\n",
        "* Layer (type):\n",
        " * Indica el nombre y el tipo de capa en la red neuronal.\n",
        " * Ejemplos: `InputLayer`, `Dense`.\n",
        "* Output Shape:\n",
        " * Muestra la forma de la salida de cada capa.\n",
        " * `None` indica que el tamaño del lote (batch size) no está especificado y puede variar.\n",
        " * Los otros números indican la dimensión de los datos en esa capa.\n",
        "* Param #:\n",
        " * Indica el número total de parámetros entrenables en esa capa.\n",
        " * Incluye los pesos y los sesgos (biases)."
      ],
      "metadata": {
        "id": "VaTVophlDM-U"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXeN8Av423GD"
      },
      "source": [
        "## 5. Entrenar el modelo\n",
        "El modelo se entrena utilizando los datos de entrenamiento. Se especifica el número de épocas y el tamaño del lote:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qCJBQx423GD"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test, y_test), shuffle=True, verbose=1)\n",
        "end_time = time.time()\n",
        "print('\\nTiempo de entrenamiento del modelo denso transcurrido: {:.5f} segundos'.format(end_time-start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Componentes Clave de la Salida del Entrenamiento**\n",
        "* Epoch: Indica la época actual del entrenamiento. Una época es un ciclo completo a través del conjunto de datos de entrenamiento. Ejemplo: `Epoch 1/20` indica que es la primera de 20 épocas.\n",
        "* `469/469 [========...]`: Muestra el progreso dentro de una época en términos de lotes (batches) procesados. 469/469 significa que se han completado 469 lotes en esa época.\n",
        "* Time per Step: Muestra el tiempo promedio por paso. Ejemplo: `11s 24ms/step` significa que cada paso tomó en promedio 11 segundos y 24 milisegundos.\n",
        "* Loss: La función de pérdida calculada en el conjunto de entrenamiento. Ejemplo: `loss: 0.2605` indica la pérdida en la primera época.\n",
        "* Accuracy: Precisión en el conjunto de entrenamiento. Ejemplo: `acc: 0.9191` significa que la precisión del modelo en el conjunto de entrenamiento es del 91.91%.\n",
        "* MSE: Error cuadrático medio en el conjunto de entrenamiento. Ejemplo: `mse: 0.0119`.\n",
        "*Validation Loss (Pérdida de Validación): La función de pérdida calculada en el conjunto de validación. Ejemplo: `val_loss: 0.1042` indica la pérdida en el conjunto de validación durante la primera época.\n",
        "* Validation Accuracy (Precisión de Validación): Precisión en el conjunto de validación. Ejemplo: `val_acc: 0.9672` significa que la precisión del modelo en el conjunto de validación es del 96.72%.\n",
        "*Validation MSE: Error cuadrático medio en el conjunto de validación.\n",
        "Ejemplo: `val_mse: 0.0049`."
      ],
      "metadata": {
        "id": "sNoRf2mJJxth"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gmv_Rhch23GD"
      },
      "source": [
        "## 6. Evaluar el proceso de entrenamiento\n",
        "Se evalúa el desempeño del modelo utilizando los datos de prueba:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gvD-GNA23GD"
      },
      "outputs": [],
      "source": [
        "# Claves del diccionario que almacena los valores de las métricas\n",
        "# registradas durante el entrenamiento de un modelo en Keras.\n",
        "history.history.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6KGq8K323GD"
      },
      "source": [
        "### Visualización de Resultados\n",
        "Se pueden graficar las métricas de precisión y pérdida para observar el desempeño del modelo durante el entrenamiento:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Evolución del Error Cuadrático Medio (MSE) durante el entrenamiento y la validación del modelo a lo largo de las épocas.**\n",
        "El objetivo de este gráfico es evaluar el rendimiento del modelo durante el entrenamiento y la validación, monitoreando el error cuadrático medio (MSE) a lo largo de las épocas. Una disminución y estabilización del MSE en ambas curvas (entrenamiento y validación) indica que el modelo está aprendiendo correctamente y generalizando bien a datos no vistos. Este gráfico ayuda a detectar problemas de sobreajuste, que se manifiestan si la curva de validación empieza a aumentar mientras la de entrenamiento sigue disminuyendo, lo que indicaría que el modelo está memorizando los datos de entrenamiento sin aprender patrones generales útiles."
      ],
      "metadata": {
        "id": "N0AYiu7hRjsx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0auFgilr23GD"
      },
      "outputs": [],
      "source": [
        "f = plt.figure(figsize=(10,10))\n",
        "plt.plot(history.history['mse'], linewidth=3, label='Train MSE')\n",
        "plt.plot(history.history['val_mse'], linewidth=3, label='Val MSE')\n",
        "plt.grid(True, which='both', linestyle='--', linewidth=1, color='#E0E0E0')\n",
        "plt.minorticks_on()\n",
        "plt.title('Evolución del Error Cuadrático Medio')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MSE')\n",
        "plt.axis([0, 30, 0, 0.02])\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Evolución de la precisión (accuracy) durante el entrenamiento y la validación de un modelo a lo largo de las épocas.**\n",
        "El objetivo de este gráfico es evaluar y comparar el rendimiento del modelo en términos de precisión (accuracy) tanto durante el entrenamiento como en la validación a lo largo de múltiples épocas. Al visualizar la evolución de la precisión en ambos conjuntos de datos, se puede verificar que el modelo está aprendiendo correctamente y generalizando bien a datos no vistos. Una estabilización de las curvas con una pequeña diferencia entre la precisión de entrenamiento y la de validación indica un buen equilibrio, sugiriendo que el modelo no está sobreajustado y es capaz de realizar predicciones precisas en datos nuevos."
      ],
      "metadata": {
        "id": "c3Gij_8zTMM0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bB-z_U3v23GE"
      },
      "outputs": [],
      "source": [
        "f = plt.figure(figsize=(10,10))\n",
        "plt.plot(history.history['acc'], linewidth=3, label='Train Accuracy')\n",
        "plt.plot(history.history['val_acc'], linewidth=3, label='Val Accuracy')\n",
        "plt.grid(True, which='both', linestyle='--', linewidth=1, color='#E0E0E0')\n",
        "plt.minorticks_on()\n",
        "plt.title('Evolución de la precisión')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.axis([0, 30, 0.75, 1])\n",
        "plt.legend(loc='lower right')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Evolución de la pérdida (loss) durante el entrenamiento y la validación de un modelo a lo largo de las épocas**\n",
        "Este gráfico sirve para evaluar y comparar la pérdida (loss) del modelo tanto durante el entrenamiento como en la validación a lo largo de múltiples épocas. Al visualizar la evolución de la pérdida en ambos conjuntos de datos, se puede verificar que el modelo está aprendiendo correctamente y mejorando su rendimiento en términos de minimizar el error. Una estabilización de las curvas de pérdida, con una pequeña diferencia entre la pérdida de entrenamiento y la de validación, sugiere que el modelo tiene un buen equilibrio entre ajuste y generalización, y que no está sobreajustado a los datos de entrenamiento."
      ],
      "metadata": {
        "id": "OroqIpqlV2vT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OuyudABd23GE"
      },
      "outputs": [],
      "source": [
        "f = plt.figure(figsize=(10,10))\n",
        "plt.plot(history.history['loss'], linewidth=3, label='Train loss')\n",
        "plt.plot(history.history['val_loss'], linewidth=3, label='Val loss')\n",
        "plt.grid(True, which='both', linestyle='--', linewidth=1, color='#E0E0E0')\n",
        "plt.minorticks_on()\n",
        "plt.title('Evolución de la pérdida')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.axis([0, 30, 0, 0.5])\n",
        "plt.legend(loc='upper right')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y13KRAF523GE"
      },
      "source": [
        "## Predicciones sobre una imagen individual"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imprime la imagen tomada del dataset, con la que se va a predecir la clase\n",
        "imagen = x_train[0].reshape(28, 28)  # Obtener el gráfico en la posición 0\n",
        "imagen = imagen / 255  # Normalizar\n",
        "plt.imshow(imagen, cmap='gray')  # Mostrar en escala de grises\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qJcRbL_IhjSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6N3EQxjW23GE"
      },
      "outputs": [],
      "source": [
        "x_single_test = x_train[0] # primera imagen del dataset, visualizada arriba\n",
        "y_single_test = y_train[0] # primera etiqueta del dataset, visualizada arriba\n",
        "x_single_test.shape = (1, x_single_test.shape[0])\n",
        "y_single_test.shape = (1, y_single_test.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkNpryJY23GE"
      },
      "outputs": [],
      "source": [
        "# Devuelve un array que contiene diez valores, cada uno correspondiente a\n",
        "# la probabilidad predicha para una de las diez posibles clases (0-9)\n",
        "model.predict(x_single_test, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sS8GndzV23GE"
      },
      "outputs": [],
      "source": [
        "# Devuelve varias métricas de rendimiento del modelo.\n",
        "model.evaluate(x_single_test, y_single_test,verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yufixI6KfyWw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}