{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ng3aOkts6YV"
      },
      "source": [
        "# IV - Transferencia de Aprendizaje (a)\n",
        " A continuación se ilustra el proceso de transferencia de aprendizaje utilizando TensorFlow y Keras con el modelo preentrenado ResNet-50 para el dataset CIFAR-100."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FqbXxNWs6YX"
      },
      "source": [
        "## Importar librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENCKaN3bs6YY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SeipmLNrs6YZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, UpSampling2D, Flatten, BatchNormalization, Dense, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import cifar100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ep09r84Ms6Ya"
      },
      "source": [
        "## Parametros de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuIrVumEs6Ya"
      },
      "outputs": [],
      "source": [
        "lr = 1.0\n",
        "epochs = 5\n",
        "batch_size = 32\n",
        "np.random.seed(14)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIfDjeThs6Ya"
      },
      "source": [
        "## Cargar y visualizar el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kFjXDV-s6Ya"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "n_classes = np.max(np.unique(y_train)) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33hXd5K2s6Yb"
      },
      "outputs": [],
      "source": [
        "num = 25\n",
        "images = x_train[:num]\n",
        "labels = y_train[:num]\n",
        "num_row = 5\n",
        "num_col = 5\n",
        "fig, axes = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\n",
        "for i in range(num):\n",
        "    ax = axes[i//num_col, i%num_col]\n",
        "    ax.imshow(images[i], cmap='gray')\n",
        "    ax.set_title('Label: {}'.format(labels[i]))\n",
        "    ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me19Q3Fjs6Yc"
      },
      "source": [
        "## Preparacion de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kyyt5SF-s6Yc"
      },
      "outputs": [],
      "source": [
        "x_train = preprocess_input(x_train)\n",
        "x_test = preprocess_input(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nw5vjJlQs6Yc"
      },
      "outputs": [],
      "source": [
        "# Tamaño del DS de entrenamiento\n",
        "# (cantidad, ancho, alto, canales)\n",
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-z_9vqBs6Yc"
      },
      "outputs": [],
      "source": [
        "y_train = to_categorical(y_train, n_classes)\n",
        "y_test = to_categorical(y_test, n_classes) # Las etiquetas se convierten a formato categórico (one-hot encoding)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ONJ25Tus6Yd"
      },
      "outputs": [],
      "source": [
        "steps_per_epoch = int(round(x_train.shape[0]/batch_size))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eZngqwbs6Yd"
      },
      "source": [
        "## Aumentar la cantidad de los datos\n",
        "Se utiliza `ImageDataGenerator` para aumentar los datos mediante transformaciones en las imágenes, como rotaciones y desplazamientos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZmPRMm9s6Yd"
      },
      "outputs": [],
      "source": [
        "datagen = ImageDataGenerator(\n",
        "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "            samplewise_center=False,  # set each sample mean to 0\n",
        "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "            samplewise_std_normalization=False,  # divide each input by its std\n",
        "            zca_whitening=False,  # apply ZCA whitening\n",
        "            zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "            rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "            # randomly shift images horizontally (fraction of total width)\n",
        "            width_shift_range=0.1,\n",
        "            # randomly shift images vertically (fraction of total height)\n",
        "            height_shift_range=0.1,\n",
        "            shear_range=0.,  # set range for random shear\n",
        "            zoom_range=0.,  # set range for random zoom\n",
        "            channel_shift_range=0.,  # set range for random channel shifts\n",
        "            # set mode for filling points outside the input boundaries\n",
        "            fill_mode='nearest',\n",
        "            cval=0.,  # value used for fill_mode = \"constant\"\n",
        "            horizontal_flip=True,  # randomly flip images\n",
        "            vertical_flip=False,  # randomly flip images\n",
        "            # set rescaling factor (applied before any other transformation)\n",
        "            rescale=None,\n",
        "            # set function that will be applied on each input\n",
        "            preprocessing_function=None,\n",
        "            # image data format, either \"channels_first\" or \"channels_last\"\n",
        "            data_format=None,\n",
        "            # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "            validation_split=0.0)\n",
        "\n",
        "datagen.fit(x_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9RmqXtZs6Yd"
      },
      "source": [
        "## Crear el modelo\n",
        " Se crea un modelo de red neuronal convolucional basado en la arquitectura ResNet-50, que ha sido preentrenado con el conjunto de datos ImageNet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTt6vA2Ls6Yd"
      },
      "outputs": [],
      "source": [
        "# ResNet50\n",
        "resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(256, 256, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yT3syDI4s6Ye"
      },
      "outputs": [],
      "source": [
        "# Identifica cuáles capas del modelo ResNet-50 preentrenado serán\n",
        "# entrenables y cuáles permanecerán fijas durante el proceso de\n",
        "# entrenamiento.\n",
        "for layer in resnet_model.layers:\n",
        "    if isinstance(layer, BatchNormalization):\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69oWrX3xs6Ye"
      },
      "outputs": [],
      "source": [
        "# Construcción del modelo\n",
        "\n",
        "# Se inicializa un modelo secuencial. Un modelo secuencial en Keras\n",
        "# permite construir una pila de capas de manera lineal, donde cada\n",
        "# capa tiene exactamente una entrada y una salida.\n",
        "model = Sequential()\n",
        "\n",
        "# Añade capa de entrada\n",
        "model.add(Input(shape=x_train.shape[1:]))\n",
        "\n",
        "# Se añaden tres capas de UpSampling2D que aumentan el tamaño de\n",
        "# las imágenes de entrada.\n",
        "model.add(UpSampling2D())\n",
        "model.add(UpSampling2D())\n",
        "model.add(UpSampling2D())\n",
        "\n",
        "# Se añade el modelo preentrenado ResNet-50\n",
        "model.add(resnet_model)\n",
        "\n",
        "# Se añade una capa de GlobalAveragePooling2D, que convierte cada\n",
        "# mapa de características en un único valor promedio, reduciendo así\n",
        "# las dimensiones de los datos y ayudando a prevenir el sobreajuste.\n",
        "model.add(GlobalAveragePooling2D())\n",
        "\n",
        "# Se añade una capa densa con 256 neuronas y una función de activación\n",
        "# ReLU (Rectified Linear Unit)\n",
        "model.add(Dense(256, activation='relu'))\n",
        "\n",
        "# Se añade una capa de Dropout con una tasa del 25%.\n",
        "model.add(Dropout(.25))\n",
        "\n",
        "# Se añade una capa de BatchNormalization, que normaliza las salidas de\n",
        "# la capa anterior, estabilizando y acelerando el proceso de entrenamiento.\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Se añade una capa densa con un número de neuronas igual al número de\n",
        "# clases (n_classes) en el problema de clasificación y una función de\n",
        "# activación softmax. Softmax convierte las salidas de la red en probabilidades\n",
        "# que suman 1, adecuada para problemas de clasificación multiclase.\n",
        "model.add(Dense(n_classes, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compilar el modelo"
      ],
      "metadata": {
        "id": "v-TDxNyIFOur"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-Jlt7fds6Ye"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['acc', 'mse'])\n",
        "model.build()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOYXfdn7s6Yf"
      },
      "source": [
        "## Entrenar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qu-kIiVTs6Yf"
      },
      "outputs": [],
      "source": [
        "# Probar con entorno de CPU y GPU\n",
        "start_time = time.time()\n",
        "train_generator = datagen.flow(x_train, y_train, batch_size=batch_size)\n",
        "\n",
        "history = model.fit(x=x_train,\n",
        "                    y=y_train,\n",
        "#                     train_generator,\n",
        "#                     steps_per_epoch=steps_per_epoch,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    workers=5,\n",
        "                    shuffle=True,\n",
        "                    verbose=1)\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "print('\\nTiempo de entrenamiento del modelo convolucional transcurrido: {:.5f} segundos'.format(end_time-start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcqTYmQNs6Yf"
      },
      "source": [
        "## Guardar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BucNQzT6s6Yf"
      },
      "outputs": [],
      "source": [
        "# El modelo entrenado se guarda en un archivo para su uso posterior.\n",
        "model.save('./src/ResNet50_cifar100.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3JYEAmas6Yf"
      },
      "outputs": [],
      "source": [
        "history.history.keys()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}