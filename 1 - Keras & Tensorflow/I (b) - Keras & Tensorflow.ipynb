{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCACIXrL_FqI"
      },
      "source": [
        "# I -  Tensorflow & Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNEb7A4-_FqJ"
      },
      "source": [
        "<center><img src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--O_kCr-s2--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/i/lkli02223oqhlac1jetz.png\" style=\"width:800px;\"/></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uUZ5m6p_FqJ"
      },
      "source": [
        "## Ejemplo I: Regla XOR en Tensorflow c/ Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rBSRWn3A_FqK"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(1234)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7u-ty07t_FqK"
      },
      "outputs": [],
      "source": [
        "epochs = 500\n",
        "learning_rate = 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kIF-iDXm_FqL"
      },
      "outputs": [],
      "source": [
        "#input_data = [[0., 0.], [0., 1.], [1., 0.], [1., 1.]]  # XOR input\n",
        "#output_data = [[1, 0], [0, 1], [0, 1], [1, 0]]  # XOR output\n",
        "input_data = np.array([[0., 0.], [0., 1.], [1., 0.], [1., 1.]])  # XOR input\n",
        "output_data = np.array([[1, 0], [0, 1], [0, 1], [1, 0]])  # XOR output\n",
        "\n",
        "output_classes = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mPgs0jfq_FqL"
      },
      "outputs": [],
      "source": [
        "# Model\n",
        "#---------------------------------------------------------------------#\n",
        "input_layer = Input(shape=(2,))\n",
        "dense_0 = Dense(10, activation='relu') (input_layer)\n",
        "dense_1 = Dense(10, activation='relu') (dense_0)\n",
        "dense_2 = Dense(10, activation='relu') (dense_1)\n",
        "output_layer = Dense(output_classes, activation='softmax') (dense_2)\n",
        "#---------------------------------------------------------------------#\n",
        "model = Model(input_layer, output_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HHE7IHyG_FqL",
        "outputId": "4258bf59-287f-45a8-efd4-c517d2877172",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │            \u001b[38;5;34m30\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m110\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m110\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m22\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m272\u001b[0m (1.06 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> (1.06 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m272\u001b[0m (1.06 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> (1.06 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "adam_optimizer = Adam(learning_rate=learning_rate)\n",
        "model.compile(optimizer=adam_optimizer, loss='binary_crossentropy')\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DjNX-93o_FqL",
        "outputId": "2ba15e82-a0cf-49dd-a6c8-07b45aa19b32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step - loss: 0.6964\n",
            "Epoch 2/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - loss: 0.6851\n",
            "Epoch 3/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.6750\n",
            "Epoch 4/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - loss: 0.6646\n",
            "Epoch 5/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.6543\n",
            "Epoch 6/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - loss: 0.6439\n",
            "Epoch 7/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - loss: 0.6332\n",
            "Epoch 8/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - loss: 0.6209\n",
            "Epoch 9/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - loss: 0.6071\n",
            "Epoch 10/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step - loss: 0.5924\n",
            "Epoch 11/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.5778\n",
            "Epoch 12/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - loss: 0.5617\n",
            "Epoch 13/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.5444\n",
            "Epoch 14/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.5268\n",
            "Epoch 15/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.5091\n",
            "Epoch 16/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.4882\n",
            "Epoch 17/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.4679\n",
            "Epoch 18/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.4462\n",
            "Epoch 19/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.4231\n",
            "Epoch 20/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.4002\n",
            "Epoch 21/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.3769\n",
            "Epoch 22/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3554\n",
            "Epoch 23/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3330\n",
            "Epoch 24/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.3108\n",
            "Epoch 25/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.2897\n",
            "Epoch 26/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.2710\n",
            "Epoch 27/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.2520\n",
            "Epoch 28/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.2330\n",
            "Epoch 29/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.2154\n",
            "Epoch 30/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.1994\n",
            "Epoch 31/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.1848\n",
            "Epoch 32/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.1705\n",
            "Epoch 33/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1570\n",
            "Epoch 34/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1449\n",
            "Epoch 35/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.1338\n",
            "Epoch 36/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.1238\n",
            "Epoch 37/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1149\n",
            "Epoch 38/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.1069\n",
            "Epoch 39/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.1005\n",
            "Epoch 40/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0946\n",
            "Epoch 41/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0890\n",
            "Epoch 42/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0842\n",
            "Epoch 43/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0798\n",
            "Epoch 44/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0755\n",
            "Epoch 45/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0715\n",
            "Epoch 46/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0675\n",
            "Epoch 47/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0639\n",
            "Epoch 48/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0603\n",
            "Epoch 49/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0569\n",
            "Epoch 50/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0535\n",
            "Epoch 51/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0501\n",
            "Epoch 52/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0468\n",
            "Epoch 53/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0435\n",
            "Epoch 54/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0399\n",
            "Epoch 55/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0364\n",
            "Epoch 56/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0331\n",
            "Epoch 57/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0304\n",
            "Epoch 58/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0278\n",
            "Epoch 59/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0254\n",
            "Epoch 60/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0232\n",
            "Epoch 61/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0211\n",
            "Epoch 62/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0192\n",
            "Epoch 63/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0174\n",
            "Epoch 64/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0158\n",
            "Epoch 65/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0144\n",
            "Epoch 66/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0131\n",
            "Epoch 67/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0118\n",
            "Epoch 68/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0108\n",
            "Epoch 69/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0098\n",
            "Epoch 70/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0089\n",
            "Epoch 71/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0081\n",
            "Epoch 72/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0074\n",
            "Epoch 73/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0068\n",
            "Epoch 74/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0062\n",
            "Epoch 75/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0057\n",
            "Epoch 76/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0052\n",
            "Epoch 77/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0048\n",
            "Epoch 78/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0044\n",
            "Epoch 79/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0041\n",
            "Epoch 80/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0038\n",
            "Epoch 81/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0035\n",
            "Epoch 82/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0033\n",
            "Epoch 83/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0030\n",
            "Epoch 84/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0028\n",
            "Epoch 85/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0026\n",
            "Epoch 86/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0025\n",
            "Epoch 87/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0023\n",
            "Epoch 88/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0022\n",
            "Epoch 89/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0021\n",
            "Epoch 90/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0020\n",
            "Epoch 91/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0019\n",
            "Epoch 92/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0018\n",
            "Epoch 93/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0017\n",
            "Epoch 94/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0016\n",
            "Epoch 95/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0016\n",
            "Epoch 96/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0015\n",
            "Epoch 97/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0014\n",
            "Epoch 98/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0014\n",
            "Epoch 99/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0013\n",
            "Epoch 100/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0013\n",
            "Epoch 101/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0012\n",
            "Epoch 102/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0012\n",
            "Epoch 103/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0012\n",
            "Epoch 104/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0011\n",
            "Epoch 105/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0011\n",
            "Epoch 106/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0011\n",
            "Epoch 107/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0010\n",
            "Epoch 108/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 9.9395e-04\n",
            "Epoch 109/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 9.6694e-04\n",
            "Epoch 110/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 9.4154e-04\n",
            "Epoch 111/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 9.1703e-04\n",
            "Epoch 112/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 8.9352e-04\n",
            "Epoch 113/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 8.7130e-04\n",
            "Epoch 114/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 8.4999e-04\n",
            "Epoch 115/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 8.2987e-04\n",
            "Epoch 116/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 8.1134e-04\n",
            "Epoch 117/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 7.9350e-04\n",
            "Epoch 118/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 7.7606e-04\n",
            "Epoch 119/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 7.5929e-04\n",
            "Epoch 120/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 7.4312e-04\n",
            "Epoch 121/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 7.2798e-04\n",
            "Epoch 122/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 7.1352e-04\n",
            "Epoch 123/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 6.9953e-04\n",
            "Epoch 124/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 6.8612e-04\n",
            "Epoch 125/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 6.7315e-04\n",
            "Epoch 126/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 6.6047e-04\n",
            "Epoch 127/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 6.4848e-04\n",
            "Epoch 128/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 6.3676e-04\n",
            "Epoch 129/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 6.2530e-04\n",
            "Epoch 130/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 6.1453e-04\n",
            "Epoch 131/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 6.0380e-04\n",
            "Epoch 132/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 5.9349e-04\n",
            "Epoch 133/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 5.8342e-04\n",
            "Epoch 134/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 5.7375e-04\n",
            "Epoch 135/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 5.6458e-04\n",
            "Epoch 136/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 5.5567e-04\n",
            "Epoch 137/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 5.4699e-04\n",
            "Epoch 138/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 5.3849e-04\n",
            "Epoch 139/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 5.3023e-04\n",
            "Epoch 140/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 5.2221e-04\n",
            "Epoch 141/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 5.1446e-04\n",
            "Epoch 142/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 5.0673e-04\n",
            "Epoch 143/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 4.9921e-04\n",
            "Epoch 144/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 4.9174e-04\n",
            "Epoch 145/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 4.8465e-04\n",
            "Epoch 146/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 4.7771e-04\n",
            "Epoch 147/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 4.7099e-04\n",
            "Epoch 148/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 4.6440e-04\n",
            "Epoch 149/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 4.5798e-04\n",
            "Epoch 150/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 4.5183e-04\n",
            "Epoch 151/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 4.4549e-04\n",
            "Epoch 152/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 4.3956e-04\n",
            "Epoch 153/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 4.3370e-04\n",
            "Epoch 154/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 4.2801e-04\n",
            "Epoch 155/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 4.2238e-04\n",
            "Epoch 156/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 4.1686e-04\n",
            "Epoch 157/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 4.1138e-04\n",
            "Epoch 158/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 4.0669e-04\n",
            "Epoch 159/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 4.0162e-04\n",
            "Epoch 160/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 3.9641e-04\n",
            "Epoch 161/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 3.9180e-04\n",
            "Epoch 162/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 3.8714e-04\n",
            "Epoch 163/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 3.8241e-04\n",
            "Epoch 164/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 3.7770e-04\n",
            "Epoch 165/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 3.7348e-04\n",
            "Epoch 166/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 3.6911e-04\n",
            "Epoch 167/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 3.6459e-04\n",
            "Epoch 168/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 3.6039e-04\n",
            "Epoch 169/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 3.5622e-04\n",
            "Epoch 170/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 3.5217e-04\n",
            "Epoch 171/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 3.4815e-04\n",
            "Epoch 172/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 3.4419e-04\n",
            "Epoch 173/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 3.4027e-04\n",
            "Epoch 174/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 3.3649e-04\n",
            "Epoch 175/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 3.3277e-04\n",
            "Epoch 176/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 3.2910e-04\n",
            "Epoch 177/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 3.2547e-04\n",
            "Epoch 178/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 3.2187e-04\n",
            "Epoch 179/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 3.1836e-04\n",
            "Epoch 180/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 3.1493e-04\n",
            "Epoch 181/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 3.1162e-04\n",
            "Epoch 182/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 3.0817e-04\n",
            "Epoch 183/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 3.0492e-04\n",
            "Epoch 184/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 3.0173e-04\n",
            "Epoch 185/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 2.9854e-04\n",
            "Epoch 186/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 2.9541e-04\n",
            "Epoch 187/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 2.9245e-04\n",
            "Epoch 188/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 2.8946e-04\n",
            "Epoch 189/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 2.8653e-04\n",
            "Epoch 190/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 2.8362e-04\n",
            "Epoch 191/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 2.8079e-04\n",
            "Epoch 192/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 2.7800e-04\n",
            "Epoch 193/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 2.7518e-04\n",
            "Epoch 194/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 2.7239e-04\n",
            "Epoch 195/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 2.6962e-04\n",
            "Epoch 196/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 2.6698e-04\n",
            "Epoch 197/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 2.6436e-04\n",
            "Epoch 198/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 2.6183e-04\n",
            "Epoch 199/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 2.5935e-04\n",
            "Epoch 200/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 2.5684e-04\n",
            "Epoch 201/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 2.5437e-04\n",
            "Epoch 202/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 2.5193e-04\n",
            "Epoch 203/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 2.4951e-04\n",
            "Epoch 204/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 2.4720e-04\n",
            "Epoch 205/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 2.4486e-04\n",
            "Epoch 206/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 2.4257e-04\n",
            "Epoch 207/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 2.4033e-04\n",
            "Epoch 208/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 2.3812e-04\n",
            "Epoch 209/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 2.3599e-04\n",
            "Epoch 210/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 2.3373e-04\n",
            "Epoch 211/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 2.3164e-04\n",
            "Epoch 212/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 2.2956e-04\n",
            "Epoch 213/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 2.2749e-04\n",
            "Epoch 214/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 2.2545e-04\n",
            "Epoch 215/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 2.2340e-04\n",
            "Epoch 216/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 2.2144e-04\n",
            "Epoch 217/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 2.1948e-04\n",
            "Epoch 218/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 2.1761e-04\n",
            "Epoch 219/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 2.1567e-04\n",
            "Epoch 220/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 2.1372e-04\n",
            "Epoch 221/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 2.1187e-04\n",
            "Epoch 222/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 2.1006e-04\n",
            "Epoch 223/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 2.0829e-04\n",
            "Epoch 224/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 2.0648e-04\n",
            "Epoch 225/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 2.0468e-04\n",
            "Epoch 226/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 2.0299e-04\n",
            "Epoch 227/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 2.0128e-04\n",
            "Epoch 228/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 1.9955e-04\n",
            "Epoch 229/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 1.9789e-04\n",
            "Epoch 230/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 1.9626e-04\n",
            "Epoch 231/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 1.9469e-04\n",
            "Epoch 232/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 1.9297e-04\n",
            "Epoch 233/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 1.9136e-04\n",
            "Epoch 234/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 1.8984e-04\n",
            "Epoch 235/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1.8829e-04\n",
            "Epoch 236/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 1.8674e-04\n",
            "Epoch 237/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 1.8522e-04\n",
            "Epoch 238/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 1.8369e-04\n",
            "Epoch 239/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 1.8222e-04\n",
            "Epoch 240/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 1.8078e-04\n",
            "Epoch 241/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 1.7935e-04\n",
            "Epoch 242/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 1.7793e-04\n",
            "Epoch 243/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 1.7651e-04\n",
            "Epoch 244/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 1.7513e-04\n",
            "Epoch 245/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 1.7375e-04\n",
            "Epoch 246/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 1.7238e-04\n",
            "Epoch 247/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 1.7106e-04\n",
            "Epoch 248/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 1.6972e-04\n",
            "Epoch 249/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 1.6843e-04\n",
            "Epoch 250/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 1.6711e-04\n",
            "Epoch 251/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 1.6582e-04\n",
            "Epoch 252/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 1.6454e-04\n",
            "Epoch 253/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 1.6330e-04\n",
            "Epoch 254/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 1.6207e-04\n",
            "Epoch 255/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 1.6086e-04\n",
            "Epoch 256/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 1.5964e-04\n",
            "Epoch 257/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 1.5845e-04\n",
            "Epoch 258/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 1.5729e-04\n",
            "Epoch 259/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 1.5612e-04\n",
            "Epoch 260/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 1.5501e-04\n",
            "Epoch 261/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 1.5387e-04\n",
            "Epoch 262/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 1.5271e-04\n",
            "Epoch 263/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 1.5160e-04\n",
            "Epoch 264/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 1.5050e-04\n",
            "Epoch 265/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1.4940e-04\n",
            "Epoch 266/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 1.4832e-04\n",
            "Epoch 267/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 1.4724e-04\n",
            "Epoch 268/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1.4617e-04\n",
            "Epoch 269/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 1.4513e-04\n",
            "Epoch 270/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 1.4411e-04\n",
            "Epoch 271/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 1.4308e-04\n",
            "Epoch 272/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 1.4209e-04\n",
            "Epoch 273/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 1.4109e-04\n",
            "Epoch 274/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 1.4010e-04\n",
            "Epoch 275/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 1.3911e-04\n",
            "Epoch 276/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 1.3813e-04\n",
            "Epoch 277/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 1.3714e-04\n",
            "Epoch 278/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 1.3619e-04\n",
            "Epoch 279/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 1.3526e-04\n",
            "Epoch 280/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 1.3435e-04\n",
            "Epoch 281/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 1.3344e-04\n",
            "Epoch 282/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 1.3252e-04\n",
            "Epoch 283/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 1.3160e-04\n",
            "Epoch 284/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 1.3072e-04\n",
            "Epoch 285/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1.2984e-04\n",
            "Epoch 286/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 1.2895e-04\n",
            "Epoch 287/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 1.2809e-04\n",
            "Epoch 288/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1.2723e-04\n",
            "Epoch 289/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 1.2638e-04\n",
            "Epoch 290/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 1.2554e-04\n",
            "Epoch 291/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 1.2472e-04\n",
            "Epoch 292/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 1.2390e-04\n",
            "Epoch 293/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 1.2308e-04\n",
            "Epoch 294/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 1.2229e-04\n",
            "Epoch 295/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 1.2147e-04\n",
            "Epoch 296/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 1.2067e-04\n",
            "Epoch 297/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 1.1990e-04\n",
            "Epoch 298/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 1.1912e-04\n",
            "Epoch 299/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 1.1835e-04\n",
            "Epoch 300/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 1.1761e-04\n",
            "Epoch 301/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 1.1685e-04\n",
            "Epoch 302/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 1.1610e-04\n",
            "Epoch 303/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 1.1537e-04\n",
            "Epoch 304/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 1.1462e-04\n",
            "Epoch 305/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 1.1390e-04\n",
            "Epoch 306/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 1.1316e-04\n",
            "Epoch 307/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 1.1246e-04\n",
            "Epoch 308/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 1.1176e-04\n",
            "Epoch 309/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 1.1108e-04\n",
            "Epoch 310/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 1.1038e-04\n",
            "Epoch 311/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 1.0970e-04\n",
            "Epoch 312/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 1.0901e-04\n",
            "Epoch 313/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 1.0836e-04\n",
            "Epoch 314/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1.0768e-04\n",
            "Epoch 315/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 1.0704e-04\n",
            "Epoch 316/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 1.0638e-04\n",
            "Epoch 317/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 1.0573e-04\n",
            "Epoch 318/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 1.0509e-04\n",
            "Epoch 319/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 1.0447e-04\n",
            "Epoch 320/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 1.0385e-04\n",
            "Epoch 321/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 1.0323e-04\n",
            "Epoch 322/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 1.0260e-04\n",
            "Epoch 323/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 1.0198e-04\n",
            "Epoch 324/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 1.0139e-04\n",
            "Epoch 325/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 1.0079e-04\n",
            "Epoch 326/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 1.0019e-04\n",
            "Epoch 327/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 9.9606e-05\n",
            "Epoch 328/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 9.9028e-05\n",
            "Epoch 329/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 9.8442e-05\n",
            "Epoch 330/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 9.7850e-05\n",
            "Epoch 331/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 9.7306e-05\n",
            "Epoch 332/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 9.6760e-05\n",
            "Epoch 333/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 9.6158e-05\n",
            "Epoch 334/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 9.5600e-05\n",
            "Epoch 335/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 9.5057e-05\n",
            "Epoch 336/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 9.4505e-05\n",
            "Epoch 337/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 9.3962e-05\n",
            "Epoch 338/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 9.3432e-05\n",
            "Epoch 339/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 9.2888e-05\n",
            "Epoch 340/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 9.2365e-05\n",
            "Epoch 341/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 9.1841e-05\n",
            "Epoch 342/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 9.1334e-05\n",
            "Epoch 343/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 9.0830e-05\n",
            "Epoch 344/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 9.0317e-05\n",
            "Epoch 345/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 8.9799e-05\n",
            "Epoch 346/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 8.9308e-05\n",
            "Epoch 347/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 8.8813e-05\n",
            "Epoch 348/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 8.8333e-05\n",
            "Epoch 349/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 8.7849e-05\n",
            "Epoch 350/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 8.7357e-05\n",
            "Epoch 351/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 8.6863e-05\n",
            "Epoch 352/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 8.6380e-05\n",
            "Epoch 353/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 8.5916e-05\n",
            "Epoch 354/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 8.5449e-05\n",
            "Epoch 355/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 8.4986e-05\n",
            "Epoch 356/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 8.4526e-05\n",
            "Epoch 357/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 8.4075e-05\n",
            "Epoch 358/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 8.3615e-05\n",
            "Epoch 359/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 8.3160e-05\n",
            "Epoch 360/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 8.2704e-05\n",
            "Epoch 361/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 8.2303e-05\n",
            "Epoch 362/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 8.1850e-05\n",
            "Epoch 363/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 8.1403e-05\n",
            "Epoch 364/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 8.0991e-05\n",
            "Epoch 365/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 8.0576e-05\n",
            "Epoch 366/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 8.0151e-05\n",
            "Epoch 367/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 7.9714e-05\n",
            "Epoch 368/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 7.9273e-05\n",
            "Epoch 369/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 7.8875e-05\n",
            "Epoch 370/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 7.8458e-05\n",
            "Epoch 371/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 7.8035e-05\n",
            "Epoch 372/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 7.7639e-05\n",
            "Epoch 373/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 7.7242e-05\n",
            "Epoch 374/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 7.6839e-05\n",
            "Epoch 375/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 7.6441e-05\n",
            "Epoch 376/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 7.6052e-05\n",
            "Epoch 377/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 7.5660e-05\n",
            "Epoch 378/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 7.5267e-05\n",
            "Epoch 379/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 7.4877e-05\n",
            "Epoch 380/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 7.4499e-05\n",
            "Epoch 381/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 7.4128e-05\n",
            "Epoch 382/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 7.3751e-05\n",
            "Epoch 383/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 7.3371e-05\n",
            "Epoch 384/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 7.3000e-05\n",
            "Epoch 385/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 7.2635e-05\n",
            "Epoch 386/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 7.2269e-05\n",
            "Epoch 387/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 7.1910e-05\n",
            "Epoch 388/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 7.1552e-05\n",
            "Epoch 389/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 7.1198e-05\n",
            "Epoch 390/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 7.0850e-05\n",
            "Epoch 391/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 7.0494e-05\n",
            "Epoch 392/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 7.0141e-05\n",
            "Epoch 393/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 6.9791e-05\n",
            "Epoch 394/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 6.9448e-05\n",
            "Epoch 395/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 6.9113e-05\n",
            "Epoch 396/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 6.8775e-05\n",
            "Epoch 397/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 6.8448e-05\n",
            "Epoch 398/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 6.8105e-05\n",
            "Epoch 399/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 6.7775e-05\n",
            "Epoch 400/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 6.7447e-05\n",
            "Epoch 401/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 6.7124e-05\n",
            "Epoch 402/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 6.6798e-05\n",
            "Epoch 403/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 6.6485e-05\n",
            "Epoch 404/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 6.6163e-05\n",
            "Epoch 405/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 6.5846e-05\n",
            "Epoch 406/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 6.5531e-05\n",
            "Epoch 407/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 6.5228e-05\n",
            "Epoch 408/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 6.4912e-05\n",
            "Epoch 409/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 6.4605e-05\n",
            "Epoch 410/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 6.4307e-05\n",
            "Epoch 411/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 6.3995e-05\n",
            "Epoch 412/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 6.3692e-05\n",
            "Epoch 413/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 6.3395e-05\n",
            "Epoch 414/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 6.3100e-05\n",
            "Epoch 415/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 6.2808e-05\n",
            "Epoch 416/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 6.2512e-05\n",
            "Epoch 417/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 6.2223e-05\n",
            "Epoch 418/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 6.1938e-05\n",
            "Epoch 419/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 6.1649e-05\n",
            "Epoch 420/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 6.1363e-05\n",
            "Epoch 421/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 6.1085e-05\n",
            "Epoch 422/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 6.0797e-05\n",
            "Epoch 423/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 6.0519e-05\n",
            "Epoch 424/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 6.0246e-05\n",
            "Epoch 425/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 5.9970e-05\n",
            "Epoch 426/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 5.9698e-05\n",
            "Epoch 427/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 5.9425e-05\n",
            "Epoch 428/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 5.9160e-05\n",
            "Epoch 429/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 5.8889e-05\n",
            "Epoch 430/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 5.8625e-05\n",
            "Epoch 431/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 5.8363e-05\n",
            "Epoch 432/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 5.8108e-05\n",
            "Epoch 433/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 5.7847e-05\n",
            "Epoch 434/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 5.7595e-05\n",
            "Epoch 435/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 5.7336e-05\n",
            "Epoch 436/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 5.7073e-05\n",
            "Epoch 437/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 5.6822e-05\n",
            "Epoch 438/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 5.6566e-05\n",
            "Epoch 439/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 5.6321e-05\n",
            "Epoch 440/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 5.6075e-05\n",
            "Epoch 441/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 5.5831e-05\n",
            "Epoch 442/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 5.5581e-05\n",
            "Epoch 443/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 5.5334e-05\n",
            "Epoch 444/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 5.5102e-05\n",
            "Epoch 445/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 5.4858e-05\n",
            "Epoch 446/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 5.4622e-05\n",
            "Epoch 447/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 5.4383e-05\n",
            "Epoch 448/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 5.4149e-05\n",
            "Epoch 449/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 5.3914e-05\n",
            "Epoch 450/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 5.3681e-05\n",
            "Epoch 451/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 5.3449e-05\n",
            "Epoch 452/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 5.3216e-05\n",
            "Epoch 453/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 5.2989e-05\n",
            "Epoch 454/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 5.2763e-05\n",
            "Epoch 455/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 5.2535e-05\n",
            "Epoch 456/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 5.2311e-05\n",
            "Epoch 457/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 5.2087e-05\n",
            "Epoch 458/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 5.1869e-05\n",
            "Epoch 459/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 5.1650e-05\n",
            "Epoch 460/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 5.1433e-05\n",
            "Epoch 461/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 5.1215e-05\n",
            "Epoch 462/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 5.0998e-05\n",
            "Epoch 463/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 5.0784e-05\n",
            "Epoch 464/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 5.0572e-05\n",
            "Epoch 465/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 5.0359e-05\n",
            "Epoch 466/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 5.0149e-05\n",
            "Epoch 467/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 4.9942e-05\n",
            "Epoch 468/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 4.9736e-05\n",
            "Epoch 469/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 4.9528e-05\n",
            "Epoch 470/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 4.9324e-05\n",
            "Epoch 471/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 4.9116e-05\n",
            "Epoch 472/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 4.8928e-05\n",
            "Epoch 473/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 4.8724e-05\n",
            "Epoch 474/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 4.8519e-05\n",
            "Epoch 475/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 4.8326e-05\n",
            "Epoch 476/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 4.8132e-05\n",
            "Epoch 477/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 4.7936e-05\n",
            "Epoch 478/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 4.7738e-05\n",
            "Epoch 479/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 4.7540e-05\n",
            "Epoch 480/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 4.7344e-05\n",
            "Epoch 481/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 4.7156e-05\n",
            "Epoch 482/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 4.6964e-05\n",
            "Epoch 483/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 4.6779e-05\n",
            "Epoch 484/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 4.6596e-05\n",
            "Epoch 485/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 4.6410e-05\n",
            "Epoch 486/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 4.6221e-05\n",
            "Epoch 487/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 4.6035e-05\n",
            "Epoch 488/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 4.5850e-05\n",
            "Epoch 489/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 4.5668e-05\n",
            "Epoch 490/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 4.5491e-05\n",
            "Epoch 491/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 4.5313e-05\n",
            "Epoch 492/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 4.5133e-05\n",
            "Epoch 493/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 4.4955e-05\n",
            "Epoch 494/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 4.4779e-05\n",
            "Epoch 495/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 4.4603e-05\n",
            "Epoch 496/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 4.4430e-05\n",
            "Epoch 497/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 4.4256e-05\n",
            "Epoch 498/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 4.4082e-05\n",
            "Epoch 499/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 4.3910e-05\n",
            "Epoch 500/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 4.3742e-05\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(input_data, output_data, epochs=epochs, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "T5fXON0a_FqM",
        "outputId": "5ed429df-628c-419d-dca1-550db5bd1aae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7cf474a11b90>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "f = plt.figure(figsize=(10,10))\n",
        "plt.plot(history.history['loss'], linewidth=3, label='Train loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper right')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Ds6NkAl1XGjy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zq1ashxM_FqM",
        "outputId": "bd70161c-588a-4ee1-c873-4895990d2bc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.0000000e+00, 1.5539195e-08],\n",
              "       [1.7967340e-10, 1.0000000e+00],\n",
              "       [7.7173201e-10, 1.0000000e+00],\n",
              "       [1.0000000e+00, 5.2398960e-11]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#model.predict([[0., 0.], [0., 1.], [1., 0.], [1., 1.]], verbose=1)\n",
        "model.predict(np.array([[0., 0.], [0., 1.], [1., 0.], [1., 1.]]), verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1VXSpSP_FqM"
      },
      "source": [
        "## Ejemplo II: Regla XOR en Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ipnD7K-e_FqM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "e1eCj1yv_FqM"
      },
      "outputs": [],
      "source": [
        "def dense( inputs , weights, bias):\n",
        "    layer = tf.matmul(inputs, weights) + bias\n",
        "    return tf.nn.relu(layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yQe6DMID_FqN"
      },
      "outputs": [],
      "source": [
        "def get_weight( shape , name ):\n",
        "    return tf.Variable(tf.random.truncated_normal(shape,stddev=0.1), name=name, trainable=True, dtype=tf.float32)\n",
        "\n",
        "shapes = [[ 2 , 10 ] ,             #0\n",
        "          [ 10 , 10 ] ,            #1\n",
        "          [ 10 , 10 ] ,            #2\n",
        "          [ 10 , output_classes ]] #3\n",
        "\n",
        "weights = []\n",
        "bias = []\n",
        "for i in range( len( shapes ) ):\n",
        "    weights.append( get_weight( shapes[ i ] , 'weight{}'.format( i ) ) )\n",
        "\n",
        "for i in range( len( shapes ) ):\n",
        "    bias.append( get_weight( [1,shapes[i][-1]], 'bias{}'.format( i ) ) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "zrvvo49g_FqN"
      },
      "outputs": [],
      "source": [
        "def trainable_variables():\n",
        "    return weights + bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "1FQvoV9A_FqN",
        "outputId": "b75e69d8-c5e7-4383-9103-5fb244253c0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<tf.Variable 'weight0:0' shape=(2, 10) dtype=float32, numpy=\n",
            "array([[ 0.10555247, -0.1438093 , -0.04279649,  0.14904861,  0.0318532 ,\n",
            "         0.03411446,  0.06985759,  0.05102892, -0.03162068,  0.06225894],\n",
            "       [ 0.01498569,  0.06665373, -0.12263101,  0.02325795, -0.09266463,\n",
            "         0.01896876,  0.07996684,  0.02956734, -0.15926997, -0.05218005]],\n",
            "      dtype=float32)>, <tf.Variable 'weight1:0' shape=(10, 10) dtype=float32, numpy=\n",
            "array([[ 0.02391917, -0.00454312,  0.19521269,  0.08007832,  0.05597046,\n",
            "         0.02316555,  0.06800447,  0.05397134,  0.17965256,  0.09127148],\n",
            "       [-0.16421136, -0.05380319,  0.04931169,  0.17031239,  0.1503336 ,\n",
            "        -0.0102577 , -0.08655339, -0.05989262, -0.06499714, -0.16805592],\n",
            "       [ 0.09420877,  0.11501401,  0.03247004, -0.11269983, -0.08279347,\n",
            "         0.03764356,  0.14844324, -0.11011612,  0.06736324,  0.06132365],\n",
            "       [-0.06952374,  0.05355349,  0.11869305, -0.07696193, -0.18793392,\n",
            "        -0.0146874 ,  0.07205959,  0.13540012, -0.05632377,  0.00092674],\n",
            "       [ 0.05240857, -0.10854441, -0.03704888,  0.08472723,  0.01649974,\n",
            "        -0.07812762,  0.16281141,  0.00496652, -0.04366833, -0.10853888],\n",
            "       [-0.12657183, -0.06054911, -0.13989697, -0.11909594,  0.09471932,\n",
            "         0.02632284,  0.11381274,  0.12839775,  0.00167443, -0.09791025],\n",
            "       [-0.07407626, -0.12618071,  0.02458443, -0.04980482,  0.05305355,\n",
            "        -0.02879105,  0.04353554,  0.03785441,  0.08833658,  0.05088567],\n",
            "       [ 0.1362537 , -0.05992587,  0.07043127, -0.06870022, -0.13511416,\n",
            "         0.04180054,  0.12055116, -0.05911606,  0.02629785,  0.13033226],\n",
            "       [-0.04564592, -0.03032384, -0.08413824,  0.06369849, -0.08327194,\n",
            "         0.0553744 , -0.11913659, -0.07160765,  0.04159394, -0.12020008],\n",
            "       [ 0.11983594,  0.13229983,  0.05767526, -0.07561778,  0.05209807,\n",
            "         0.00279792,  0.09531187,  0.05898003, -0.07984884, -0.00593072]],\n",
            "      dtype=float32)>, <tf.Variable 'weight2:0' shape=(10, 10) dtype=float32, numpy=\n",
            "array([[ 1.68428183e-01, -3.66908088e-02, -1.29978001e-01,\n",
            "        -1.55556379e-02, -6.21204190e-02,  5.95332198e-02,\n",
            "         2.26660259e-02,  7.35366940e-02, -1.83431089e-01,\n",
            "        -1.96419641e-01],\n",
            "       [-6.38803914e-02,  1.30877867e-01, -1.80476811e-02,\n",
            "        -1.24853984e-01,  9.67460200e-02,  9.00145695e-02,\n",
            "         2.05773264e-02,  3.93070430e-02,  1.34900615e-01,\n",
            "        -9.27151665e-02],\n",
            "       [-9.62141156e-02, -5.95934801e-02,  6.00516200e-02,\n",
            "        -1.56792309e-02,  5.95176704e-02, -1.45115614e-01,\n",
            "        -1.40343057e-02, -1.20713077e-01,  1.97200388e-01,\n",
            "         1.35247320e-01],\n",
            "       [-1.15073420e-01, -6.45871013e-02, -5.75383659e-03,\n",
            "        -1.39110535e-01,  7.14485273e-02,  1.66429430e-02,\n",
            "         1.27143517e-01,  1.20025948e-01, -1.13642193e-01,\n",
            "        -3.31892306e-03],\n",
            "       [ 1.09938337e-02, -1.16184704e-01,  7.01008886e-02,\n",
            "        -2.51972862e-02, -3.56412902e-02,  1.68887615e-01,\n",
            "        -7.78317172e-03,  1.79161593e-01,  8.33038315e-02,\n",
            "         2.71329973e-02],\n",
            "       [ 4.39262167e-02,  1.56152830e-01, -6.91554472e-02,\n",
            "         5.70509806e-02,  1.19438767e-01, -4.47817482e-02,\n",
            "         3.09995692e-02, -3.71592939e-02, -3.98081206e-02,\n",
            "        -9.09639150e-02],\n",
            "       [-8.72686654e-02,  9.61273722e-03,  1.50881605e-02,\n",
            "        -2.38948204e-02, -1.04549125e-01,  8.41031142e-05,\n",
            "        -4.18679714e-02,  7.03102862e-03,  1.53414477e-02,\n",
            "         2.89182607e-02],\n",
            "       [-1.77957699e-01, -1.63638517e-01,  4.07223888e-02,\n",
            "        -6.92025274e-02,  4.38604085e-03, -9.68703851e-02,\n",
            "        -6.89134374e-02,  1.19083099e-01, -2.45964881e-02,\n",
            "         1.67963386e-01],\n",
            "       [-1.34903952e-01, -3.35858725e-02,  5.50509356e-02,\n",
            "        -7.90648684e-02,  1.36397690e-01, -2.69426145e-02,\n",
            "         1.70572624e-01, -1.08892851e-01,  5.30049147e-04,\n",
            "        -4.89479527e-02],\n",
            "       [ 5.66208325e-02,  1.54814043e-05,  1.90257117e-01,\n",
            "        -1.00582890e-01,  5.64610548e-02,  1.10950433e-01,\n",
            "         3.99475992e-02,  3.45082209e-02,  4.38971492e-03,\n",
            "         3.04430816e-02]], dtype=float32)>, <tf.Variable 'weight3:0' shape=(10, 2) dtype=float32, numpy=\n",
            "array([[ 0.02161844, -0.00126611],\n",
            "       [ 0.07036059,  0.10305005],\n",
            "       [-0.16231747,  0.06364294],\n",
            "       [-0.06082878,  0.04857417],\n",
            "       [-0.0306166 , -0.07511494],\n",
            "       [ 0.08412065,  0.16664696],\n",
            "       [ 0.19063103, -0.13016547],\n",
            "       [ 0.0712846 , -0.04990239],\n",
            "       [ 0.10879908, -0.00286217],\n",
            "       [-0.0604078 , -0.18066317]], dtype=float32)>]\n"
          ]
        }
      ],
      "source": [
        "print(weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_MyQN5S9_FqN"
      },
      "outputs": [],
      "source": [
        "def model( x ) :\n",
        "    x = tf.cast( x , dtype=tf.float32 )\n",
        "    d0 = dense(  x, weights[0], bias[0] )\n",
        "    d1 = dense( d0, weights[1], bias[1] )\n",
        "    d2 = dense( d1, weights[2], bias[2] )\n",
        "    d3 = tf.matmul(d2 , weights[3]) + bias[3]\n",
        "    return tf.nn.softmax( d3 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "VJQFhMT1_FqN"
      },
      "outputs": [],
      "source": [
        "def loss( pred , target ):\n",
        "    return tf.losses.binary_crossentropy( target , pred )\n",
        "\n",
        "optimizer = tf.optimizers.Adam( learning_rate )\n",
        "\n",
        "def train_step( model, inputs , outputs ):\n",
        "    with tf.GradientTape() as tape:\n",
        "        current_loss = loss( model( inputs ), outputs)\n",
        "    grads = tape.gradient( current_loss , trainable_variables() )\n",
        "    optimizer.apply_gradients( zip( grads , trainable_variables() ) )\n",
        "    print( tf.reduce_mean( current_loss ) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "6UJ3ryOX_FqN",
        "outputId": "d2ea455e-c92b-43fe-cf1e-f1ed80da4a79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0.69383883, shape=(), dtype=float32)\n",
            "tf.Tensor(0.6932465, shape=(), dtype=float32)\n",
            "tf.Tensor(0.6930961, shape=(), dtype=float32)\n",
            "tf.Tensor(0.69318646, shape=(), dtype=float32)\n",
            "tf.Tensor(0.69323766, shape=(), dtype=float32)\n",
            "tf.Tensor(0.69305754, shape=(), dtype=float32)\n",
            "tf.Tensor(0.692814, shape=(), dtype=float32)\n",
            "tf.Tensor(0.6925715, shape=(), dtype=float32)\n",
            "tf.Tensor(0.6923193, shape=(), dtype=float32)\n",
            "tf.Tensor(0.6921464, shape=(), dtype=float32)\n",
            "tf.Tensor(0.69194824, shape=(), dtype=float32)\n",
            "tf.Tensor(0.6914041, shape=(), dtype=float32)\n",
            "tf.Tensor(0.6908518, shape=(), dtype=float32)\n",
            "tf.Tensor(0.69006217, shape=(), dtype=float32)\n",
            "tf.Tensor(0.68904024, shape=(), dtype=float32)\n",
            "tf.Tensor(0.68786865, shape=(), dtype=float32)\n",
            "tf.Tensor(0.68627954, shape=(), dtype=float32)\n",
            "tf.Tensor(0.68436843, shape=(), dtype=float32)\n",
            "tf.Tensor(0.6820084, shape=(), dtype=float32)\n",
            "tf.Tensor(0.67981535, shape=(), dtype=float32)\n",
            "tf.Tensor(0.6767552, shape=(), dtype=float32)\n",
            "tf.Tensor(0.6732869, shape=(), dtype=float32)\n",
            "tf.Tensor(0.668832, shape=(), dtype=float32)\n",
            "tf.Tensor(0.66444486, shape=(), dtype=float32)\n",
            "tf.Tensor(0.6587438, shape=(), dtype=float32)\n",
            "tf.Tensor(0.65232307, shape=(), dtype=float32)\n",
            "tf.Tensor(0.64499176, shape=(), dtype=float32)\n",
            "tf.Tensor(0.6364425, shape=(), dtype=float32)\n",
            "tf.Tensor(0.62613577, shape=(), dtype=float32)\n",
            "tf.Tensor(0.6160908, shape=(), dtype=float32)\n",
            "tf.Tensor(0.6047565, shape=(), dtype=float32)\n",
            "tf.Tensor(0.5913225, shape=(), dtype=float32)\n",
            "tf.Tensor(0.57490486, shape=(), dtype=float32)\n",
            "tf.Tensor(0.5589531, shape=(), dtype=float32)\n",
            "tf.Tensor(0.54280937, shape=(), dtype=float32)\n",
            "tf.Tensor(0.52112544, shape=(), dtype=float32)\n",
            "tf.Tensor(0.50014126, shape=(), dtype=float32)\n",
            "tf.Tensor(0.47583106, shape=(), dtype=float32)\n",
            "tf.Tensor(0.44951072, shape=(), dtype=float32)\n",
            "tf.Tensor(0.41946018, shape=(), dtype=float32)\n",
            "tf.Tensor(0.38627052, shape=(), dtype=float32)\n",
            "tf.Tensor(0.35375178, shape=(), dtype=float32)\n",
            "tf.Tensor(0.31898165, shape=(), dtype=float32)\n",
            "tf.Tensor(0.2830326, shape=(), dtype=float32)\n",
            "tf.Tensor(0.24936335, shape=(), dtype=float32)\n",
            "tf.Tensor(0.21690935, shape=(), dtype=float32)\n",
            "tf.Tensor(0.18464018, shape=(), dtype=float32)\n",
            "tf.Tensor(0.16096105, shape=(), dtype=float32)\n",
            "tf.Tensor(0.13503663, shape=(), dtype=float32)\n",
            "tf.Tensor(0.11359581, shape=(), dtype=float32)\n",
            "tf.Tensor(0.096058786, shape=(), dtype=float32)\n",
            "tf.Tensor(0.07932296, shape=(), dtype=float32)\n",
            "tf.Tensor(0.06560945, shape=(), dtype=float32)\n",
            "tf.Tensor(0.054383244, shape=(), dtype=float32)\n",
            "tf.Tensor(0.04433623, shape=(), dtype=float32)\n",
            "tf.Tensor(0.036107775, shape=(), dtype=float32)\n",
            "tf.Tensor(0.029679835, shape=(), dtype=float32)\n",
            "tf.Tensor(0.02456205, shape=(), dtype=float32)\n",
            "tf.Tensor(0.020214966, shape=(), dtype=float32)\n",
            "tf.Tensor(0.016546637, shape=(), dtype=float32)\n",
            "tf.Tensor(0.013591589, shape=(), dtype=float32)\n",
            "tf.Tensor(0.011255875, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0093896445, shape=(), dtype=float32)\n",
            "tf.Tensor(0.007895548, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0066932617, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0057111722, shape=(), dtype=float32)\n",
            "tf.Tensor(0.004904503, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0042528766, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0037099228, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0032558024, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0028765146, shape=(), dtype=float32)\n",
            "tf.Tensor(0.002556651, shape=(), dtype=float32)\n",
            "tf.Tensor(0.002286062, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0020576552, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0018686133, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0017105152, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0015766593, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0014615504, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0013612565, shape=(), dtype=float32)\n",
            "tf.Tensor(0.001273034, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0011960284, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0011280205, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0010675238, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0010134703, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00096506765, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0009218521, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0008833826, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00084895035, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0008178387, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00078970415, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0007640545, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00074074, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0007192311, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0006993711, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0006809734, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00066390354, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0006479975, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0006331656, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0006195195, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00060686533, shape=(), dtype=float32)\n",
            "tf.Tensor(0.000594972, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0005838842, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00057344517, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0005635507, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0005541782, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0005452533, shape=(), dtype=float32)\n",
            "tf.Tensor(0.000537141, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0005296774, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0005224154, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0005153622, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0005085552, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00050203165, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0004957542, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0004896185, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0004836917, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00047810032, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00047265063, shape=(), dtype=float32)\n",
            "tf.Tensor(0.000467365, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0004622136, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00045729318, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00045249957, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0004478104, shape=(), dtype=float32)\n",
            "tf.Tensor(0.000443151, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00043877476, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00043462223, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00043059647, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00042667508, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0004228357, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00041900383, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00041531358, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00041164568, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0004080226, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00040444426, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0004008585, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0003973697, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00039386604, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00039039965, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00038711962, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00038394396, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00038074597, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00037756292, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00037449918, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00037147268, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00036854314, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00036562106, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00036272878, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0003597844, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00035686977, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0003540521, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0003513015, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00034859564, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00034584507, shape=(), dtype=float32)\n",
            "tf.Tensor(0.000343184, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00034045585, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00033783214, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00033532013, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00033276345, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00033028127, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00032779912, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0003253095, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00032287207, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00032039743, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00031801965, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00031570156, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00031337602, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00031110266, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00030890378, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00030669005, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00030451355, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00030237433, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00030022027, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00029810343, shape=(), dtype=float32)\n",
            "tf.Tensor(0.000296009, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00029398908, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00029195426, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00028997904, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00028800388, shape=(), dtype=float32)\n",
            "tf.Tensor(0.000286066, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00028412067, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00028219767, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0002802523, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00027834426, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00027651075, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0002746176, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00027268723, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00027084624, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00026909474, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0002672687, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00026547248, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00026367628, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0002619248, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0002602031, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00025852615, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0002568194, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00025514245, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00025350277, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00025184074, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0002502085, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00024856138, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00024698133, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00024537896, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00024381383, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00024225615, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00024067613, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00023912593, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0002376875, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00023615966, shape=(), dtype=float32)\n",
            "tf.Tensor(0.000234684, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00023322325, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0002317327, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00023026449, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00022886333, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0002274175, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00022601637, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0002246078, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00022322158, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00022182048, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00022050133, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00021915985, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00021781091, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00021646943, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00021512795, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00021383862, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00021255677, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0002112749, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00020998564, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0002087634, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00020753373, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00020628914, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0002050222, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00020377018, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00020262248, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00020143007, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00020024512, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00019903782, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00019785287, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00019671266, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00019557241, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00019440983, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00019325472, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00019218154, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00019108604, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00019000545, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00018892485, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00018782934, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00018680836, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00018576502, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00018472914, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00018370817, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00018263505, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00018163642, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00018064525, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00017966155, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00017867784, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00017764942, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00017668807, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00017569693, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00017469088, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00017373699, shape=(), dtype=float32)\n",
            "tf.Tensor(0.000172798, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00017183667, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00017090514, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00016999595, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00016907934, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00016814037, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00016727591, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0001663891, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00016549484, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00016458568, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00016373611, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00016287912, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00016196998, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00016110553, shape=(), dtype=float32)\n",
            "tf.Tensor(0.000160256, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00015942134, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00015857181, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00015775952, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0001569398, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00015612008, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0001553227, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00015448808, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00015372051, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00015288588, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00015210341, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0001513284, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0001505683, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00014980073, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00014901083, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00014827307, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00014751298, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00014675286, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00014603004, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00014529227, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00014458435, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00014381681, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00014310886, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00014240094, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00014166319, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00014096271, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00014026967, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0001395692, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00013888362, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00013821296, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00013754974, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00013686415, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00013620095, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00013550793, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00013485215, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00013421128, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00013356298, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0001329072, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00013225146, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00013162551, shape=(), dtype=float32)\n",
            "tf.Tensor(0.000131007, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00013039596, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00012973274, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00012912169, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00012851809, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00012789214, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00012728854, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00012668494, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00012606646, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00012548521, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00012489653, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00012430038, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00012371171, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0001231379, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00012257158, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00012198289, shape=(), dtype=float32)\n",
            "tf.Tensor(0.000121438905, shape=(), dtype=float32)\n",
            "tf.Tensor(0.000120880024, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0001203137, shape=(), dtype=float32)\n",
            "tf.Tensor(0.000119725024, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00011918104, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00011865942, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00011810799, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00011757147, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00011702004, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00011649842, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00011596936, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00011546264, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00011493356, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0001143896, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00011388288, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00011336127, shape=(), dtype=float32)\n",
            "tf.Tensor(0.000112854555, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00011234041, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0001118635, shape=(), dtype=float32)\n",
            "tf.Tensor(0.000111356785, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00011085752, shape=(), dtype=float32)\n",
            "tf.Tensor(0.000110350804, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00010988135, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00010937464, shape=(), dtype=float32)\n",
            "tf.Tensor(0.000108882836, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00010840594, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00010793649, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00010743723, shape=(), dtype=float32)\n",
            "tf.Tensor(0.000106960324, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00010650579, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00010605868, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00010560414, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00010513469, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00010468014, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00010421814, shape=(), dtype=float32)\n",
            "tf.Tensor(0.000103771046, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0001033016, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00010284706, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00010242977, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00010198268, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00010155795, shape=(), dtype=float32)\n",
            "tf.Tensor(0.000101110854, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00010067121, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00010025392, shape=(), dtype=float32)\n",
            "tf.Tensor(9.982174e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(9.9389545e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(9.898716e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(9.856243e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(9.813769e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(9.7735305e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(9.731802e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(9.6938005e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(9.6528165e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(9.611089e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(9.573086e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(9.533593e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(9.4933544e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(9.455353e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(9.415114e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(9.3748764e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(9.336874e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(9.299617e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(9.2616145e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(9.225847e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(9.186355e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(9.149097e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(9.1148206e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(9.077563e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(9.040307e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(9.0037945e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(8.968772e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(8.932261e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(8.895749e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(8.861472e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(8.8242145e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(8.789939e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(8.754172e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(8.72064e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(8.684874e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(8.652832e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(8.6163214e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(8.58428e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(8.547768e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(8.514982e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(8.482196e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(8.4479194e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(8.415879e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(8.383093e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(8.351052e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(8.3197556e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(8.285479e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(8.254184e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(8.222888e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(8.1901024e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(8.159551e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(8.129747e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(8.097705e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(8.064919e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(8.0373495e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(8.005308e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(7.975504e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(7.9449535e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(7.9151476e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(7.8860874e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(7.857027e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(7.823496e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(7.795181e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(7.765376e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(7.737061e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(7.708746e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(7.679686e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(7.6506265e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(7.621566e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(7.5932505e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(7.565681e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(7.537366e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(7.511287e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(7.482972e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(7.4539115e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(7.4285774e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(7.399518e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(7.370458e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(7.345868e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(7.3175535e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(7.2929644e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(7.263904e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(7.23857e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(7.211e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(7.186412e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(7.160332e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(7.1327624e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(7.108173e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(7.082094e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(7.058995e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(7.03217e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(7.007582e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(6.9815025e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(6.9561676e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(6.933069e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(6.9062444e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(6.8838905e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(6.8600464e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(6.833968e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(6.810123e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(6.78628e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(6.761691e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(6.738592e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(6.7154935e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(6.6909044e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(6.667061e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(6.6454515e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(6.6238434e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(6.597019e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(6.574665e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(6.554547e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(6.527723e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(6.50686e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(6.485251e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(6.461407e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(6.439054e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(6.418936e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(6.3950916e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(6.3727384e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(6.3518746e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(6.332502e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(6.307168e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(6.2877945e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(6.265441e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(6.246068e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(6.225205e-05, shape=(), dtype=float32)\n",
            "tf.Tensor(6.202106e-05, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "for e in range( epochs ):\n",
        "    train_step( model, input_data , output_data )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "q0uBvQ5__FqN",
        "outputId": "31f420b3-e3fa-4af6-9f61-c94283bc6b3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<tf.Variable 'weight0:0' shape=(2, 10) dtype=float32, numpy=\n",
            "array([[ 0.39576203, -0.1438093 , -0.04279649,  0.39734274, -0.51446897,\n",
            "         0.03411446,  0.42880455,  0.45815694, -0.03162068,  0.44576088],\n",
            "       [ 0.39578542,  0.06665373, -0.12263101,  0.39731732, -0.51445854,\n",
            "         0.01896876,  0.45774812,  0.4575576 , -0.15926997,  0.37040287]],\n",
            "      dtype=float32)>, <tf.Variable 'weight1:0' shape=(10, 10) dtype=float32, numpy=\n",
            "array([[ 8.91981721e-01,  7.07906842e-01,  9.76827681e-01,\n",
            "         8.00783187e-02, -2.17734557e-02, -7.19255567e-01,\n",
            "         7.53757834e-01,  8.54328930e-01,  1.79652557e-01,\n",
            "         3.97329554e-02],\n",
            "       [-1.64211363e-01, -5.38031869e-02,  4.93116863e-02,\n",
            "         1.70312390e-01,  1.50333598e-01, -1.02576986e-02,\n",
            "        -8.65533873e-02, -5.98926209e-02, -6.49971366e-02,\n",
            "        -1.68055922e-01],\n",
            "       [ 9.42087695e-02,  1.15014009e-01,  3.24700437e-02,\n",
            "        -1.12699829e-01, -8.27934667e-02,  3.76435556e-02,\n",
            "         1.48443237e-01, -1.10116124e-01,  6.73632398e-02,\n",
            "         6.13236502e-02],\n",
            "       [ 7.88659751e-01,  7.54043937e-01,  8.79771173e-01,\n",
            "        -7.69619346e-02, -2.63900220e-01, -7.38484800e-01,\n",
            "         7.28430510e-01,  9.23992872e-01, -5.63237742e-02,\n",
            "        -5.06141894e-02],\n",
            "       [ 6.54061139e-01,  4.04556185e-01, -3.98471504e-01,\n",
            "         8.47272277e-02, -5.62305339e-02, -5.94995320e-01,\n",
            "         7.07445621e-01,  5.06698310e-01, -4.36683260e-02,\n",
            "        -1.60108402e-01],\n",
            "       [-1.26571834e-01, -6.05491064e-02, -1.39896974e-01,\n",
            "        -1.19095936e-01,  9.47193205e-02,  2.63228398e-02,\n",
            "         1.13812737e-01,  1.28397748e-01,  1.67442940e-03,\n",
            "        -9.79102477e-02],\n",
            "       [-2.71582395e-01, -3.24696183e-01,  2.37443537e-01,\n",
            "        -4.98048216e-02,  8.48734155e-02,  5.09681463e-01,\n",
            "        -1.69039592e-01, -1.48036942e-01,  8.83365795e-02,\n",
            "        -7.01369718e-04],\n",
            "       [-5.55169620e-02, -1.96905121e-01,  1.36423275e-01,\n",
            "        -6.87002242e-02, -1.16112024e-01,  5.86716115e-01,\n",
            "        -6.00290485e-02, -1.89710021e-01,  2.62978524e-02,\n",
            "         7.87399188e-02],\n",
            "       [-4.56459187e-02, -3.03238425e-02, -8.41382369e-02,\n",
            "         6.36984929e-02, -8.32719430e-02,  5.53744026e-02,\n",
            "        -1.19136594e-01, -7.16076493e-02,  4.15939428e-02,\n",
            "        -1.20200075e-01],\n",
            "       [-9.03775468e-02,  4.99759801e-03,  9.05051529e-02,\n",
            "        -7.56177828e-02, -2.17111818e-02,  5.59857547e-01,\n",
            "        -9.65009406e-02, -2.75342781e-02, -7.98488408e-02,\n",
            "        -5.74788451e-02]], dtype=float32)>, <tf.Variable 'weight2:0' shape=(10, 10) dtype=float32, numpy=\n",
            "array([[-3.02650392e-01, -5.08053780e-01, -6.40435815e-01,\n",
            "        -4.87168342e-01,  7.44930983e-01, -3.97705227e-01,\n",
            "         2.26660259e-02,  8.84320080e-01, -2.43360639e-01,\n",
            "        -1.96419641e-01],\n",
            "       [-7.35644221e-01, -5.26263118e-01, -6.21754706e-01,\n",
            "        -7.11900413e-01,  9.04814422e-01, -5.55560291e-01,\n",
            "         2.05773264e-02,  8.84245455e-01,  7.51034617e-02,\n",
            "        -9.27151665e-02],\n",
            "       [-6.09045684e-01, -7.19471991e-01, -5.43624759e-01,\n",
            "        -6.44771099e-01,  8.73065650e-01, -6.59953535e-01,\n",
            "        -1.40343057e-02,  7.78059363e-01,  2.49688447e-01,\n",
            "         1.35247320e-01],\n",
            "       [-1.15073420e-01, -6.45871013e-02, -5.75383659e-03,\n",
            "        -1.39110535e-01,  7.14485273e-02,  1.66429430e-02,\n",
            "         1.27143517e-01,  1.20025948e-01, -1.13642193e-01,\n",
            "        -3.31892306e-03],\n",
            "       [-1.83596686e-02, -3.89043130e-02,  1.58772722e-01,\n",
            "         6.02061562e-02, -1.17820375e-01,  2.51661807e-01,\n",
            "        -7.78317172e-03,  8.33651498e-02,  2.36969851e-02,\n",
            "         2.71329973e-02],\n",
            "       [ 7.53791153e-01,  8.84960830e-01,  7.09545374e-01,\n",
            "         8.15586686e-01, -3.35658371e-01,  7.34382093e-01,\n",
            "         3.09995692e-02, -4.37707752e-01, -9.89343002e-02,\n",
            "        -9.09639150e-02],\n",
            "       [-5.34656763e-01, -4.44820493e-01, -4.83922541e-01,\n",
            "        -4.66820091e-01,  7.02451944e-01, -4.40792233e-01,\n",
            "        -4.18679714e-02,  8.42031538e-01, -4.45354171e-02,\n",
            "         2.89182607e-02],\n",
            "       [-7.65971005e-01, -7.91190863e-01, -6.05661809e-01,\n",
            "        -6.99821353e-01,  8.16352069e-01, -7.26977170e-01,\n",
            "        -6.89134374e-02,  1.02589202e+00, -8.40706378e-02,\n",
            "         1.67963386e-01],\n",
            "       [-1.34903952e-01, -3.35858725e-02,  5.50509356e-02,\n",
            "        -7.90648684e-02,  1.36397690e-01, -2.69426145e-02,\n",
            "         1.70572624e-01, -1.08892851e-01,  5.30049147e-04,\n",
            "        -4.89479527e-02],\n",
            "       [ 1.18630361e-02, -4.82578613e-02,  1.39800102e-01,\n",
            "        -1.50321871e-01,  2.74001192e-02,  6.14783913e-02,\n",
            "         3.99475992e-02,  8.09711069e-02,  4.38971492e-03,\n",
            "         3.04430816e-02]], dtype=float32)>, <tf.Variable 'weight3:0' shape=(10, 2) dtype=float32, numpy=\n",
            "array([[-0.78299665,  0.80334926],\n",
            "       [-0.71553034,  0.8889412 ],\n",
            "       [-0.85392636,  0.75525224],\n",
            "       [-0.82414764,  0.8118932 ],\n",
            "       [ 0.7860751 , -0.89180666],\n",
            "       [-0.7083029 ,  0.95907074],\n",
            "       [ 0.19063103, -0.13016547],\n",
            "       [ 0.8613222 , -0.83994   ],\n",
            "       [ 0.04905426,  0.05688265],\n",
            "       [-0.0604078 , -0.18066317]], dtype=float32)>]\n"
          ]
        }
      ],
      "source": [
        "print(weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Q6prTC4F_FqN",
        "outputId": "f69e1cb7-8e75-429f-aec7-f0469fc67a4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
              "array([[9.9988341e-01, 1.1654033e-04],\n",
              "       [4.4726989e-05, 9.9995530e-01],\n",
              "       [3.9534472e-05, 9.9996042e-01],\n",
              "       [9.9995363e-01, 4.6428333e-05]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "model([[0., 0.], [0., 1.], [1., 0.], [1., 1.]])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}